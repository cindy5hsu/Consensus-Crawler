 Hello. I know it's a little bit quiet after lunch, but we're time to get started. I'm excited to talk about next generation money movement on top of Aptos. And so if you think about crypto, it's been used a lot for speculation, for also just kind of understanding how the technology can play a role in our lives. But what we started to think about at Aptos is, how is money movement going to really impact the next generation of crypto users going forward? And so the focus points for this particular talk are in three different areas. Trading, stablecoins, and real-world assets. And the reason why we focus on these particular aspects is because we believe that they bring the most value to users in the coming years. There's a lot of utility to be had in terms of mass adoption of social integration with networks, with integration with even different kinds of creator platforms, as well as other opportunities for how every single internet protocol in the world today can leverage blockchain technology. But these are the focus points for us in the coming future, and we'll kind of explain why. When it comes to trading, that's, I think, what all high-performance chains aspire to. And so for those of you who have followed the success of both centralized and decentralized trading platforms, it's clear that this is an important use case for every one of us going forward in the future. And for blockchains, we should be providing the best infrastructure possible for leveraging asset movement on every kind of exchange, whether it's spot changes, perp exchanges, as well as other novel products around how we move these assets and we can actually interact with each other on this. And so from a blockchain perspective, what that means is when you think about our tick-to-trade times, what is the time when price information goes from around the world into the network and then being able to act upon that price change immediately, not with a delay of seconds or minutes, not with fees that are in the dollars or even tens of cents, that's not scalable. If we compare it to today's existing platforms, you have NASDAQ, you have the NYC, you have the London Stock Exchange, each of these platforms supports trillions of dollars of daily movement. And for this to happen in the blockchain space, it requires very, very high performance infrastructure, infrastructure that kind of rivals those products in market today. But it's much more challenging for a decentralized infrastructure to do that. That computation is repeatable. It is something that requires a deep technical mind to solve. And for this, you know, it requires very, very low block times. Today, Aptos is the lowest block times in the market, as shown here. You have, you know, under 200 millisecond block times, much, much faster than everybody else out there. This allows us to react much faster. Traders can get the arbitrage opportunities, they can take advantage of the spreads between other decentralized infrastructure, they can even start to really compete with the centralized exchanges around today. And so for this, it really means a lot of deep technical innovation. One thing is, how do you kind of your consensus protocol operate at mass optimal consensus latency? For us, that's three hops. One time for someone to propose a block, someone to vote on it, and the second time, the third time to confirm that transaction. One and a half network round trips. This means that if you have a sub 200 millisecond block time, it takes about 300 milliseconds or less for that trade to go through in today's system. As we go down to under 100 milliseconds of block time, we're talking about 150 milliseconds, which is a lot faster and starts to really rival that experience you see in centralized exchanges today. Another thing is, we don't have to wait for those trades to happen. You see a price action, you want to act immediately upon it. You don't have to wait those 150 milliseconds. And so for that, be able to support what we call event-driven transactions. It means you can submit your price feed action early and say, well, look, if Bitcoin moves over 100,000 today, I want to sell a little bit of Bitcoin. And as soon as that price action is discovered on chain, the infrastructure will then take advantage of your trade, execute upon it immediately, and not have to wait with any delay for that going forward. This is a very novel thing that's going to be possible in the coming months on top of a system like Aptos. The third thing that's important for trading infrastructure is what we call Aptos Intents. For those who've been following Intents, Intents is the idea that you can kind of put an open order on any blockchain like Aptos, and anyone can fill this order. So what it does essentially is turn the entire order book live for the network. Anyone can fill that order. Aggregators can fill it. You can have centralized exchanges filling it. You have decentralized exchanges filling it. Anybody can kind of take advantage of that. And that is a very powerful tool for aggregating liquidity access as well as orders into one place. The next is around stablecoins. And for move, it's a new language. It's something that we worked on at Facebook back in 2018, developed over time. We now have move to in Aptos. It's something that's been released, and we'll talk about a little bit more later. But we're very proud to say that both USDT and USDC are live on Aptos today. The only move chain with those both. And in terms of move stablecoins, you see about $839 million of stables now live on top of Aptos as well. We're very excited to see as well other stables coming to Aptos. We're the only L1 protocol working with the Hong Kong dollar today, just given we're in Hong Kong, that would be appropriate to share. And we're also in discussions about seeing other stables come on board, like AED out of the Middle East. The reason why we care a lot about money movement is because it's very important for an economy to flourish, for trade to happen. And Aptos is the cheapest place for that money movement to occur. This is a screenshot of the gas fees now for money movement on USDT. And you can see that Aptos is 10 to 10,000 times cheaper than any other blockchains that are going to move money on. And this means you can do things that just aren't possible in other networks. You can support microfinancing applications. I can loan you a dollar and you can pay me back in two cent increments, 50 times. And everything, that entire transaction flow is gonna be cheaper than a cent. The next thing is you can imagine a world where you pay for content. Today, there's a subscription-based model. If I sign up for the Wall Street Journal or for the Times of India, I pay a flat fee for a period of time. And it's just one article I might want to read. Instead, you could have a model where you pay a couple of cents for that article. That gets transacted on chain. That goes to the publisher. And now I don't have to get a subscription for that. Now, it requires that very low cost of transaction so that these low costs of the articles are very feasible. It also requires a very scalable network. That's something that Aptos does really, really well. The last use case we have for stablecoins is around decentralized physical infrastructure or deepin. Deepin networks are really about how do we kind of allow our shared resources to be used by others and being compensated for it. So whether it's gonna be AI clusters being leveraged by certain software providers. It could be you using my wireless network or my wireless access. And in the back end, what's happening is you have the payments infrastructure, very similar to the way you think about AWS or Google Cloud Services or Azure going forward. And so providing an infrastructure that supports that, an extremely very fine granular payment is really important. The last piece here is that even forget money movement for a second. If you think about things like loyalty programs, which are very, very low value transactions, they may even be, you know, subsets. You have to have a network that supports that very, very low cost in order for this to be very sustainable and work well for kind of this large scale applications of loyalty programs. The last area in this kind of bucket, the trilemma we call it, is gonna be RWAs. And RWAs is an asset class that's gonna grow to $40 trillion by 2030. It is something that is being looked at very intensely by a number of large asset managers, as well as even those who are just looking to innovate in the space. We've been very excited to see that Apollo, BlackRock, Franklin Templeton, Brevin Howard are all issuing different kind of tokenized assets on top of Aptos. They're experimenting, trying to understand the demand for these products and also how they would work in practice. Today, I think there's more than a billion dollars of funds are tokenized on different products today. And we expect that number to grow extremely fast in the near future. We're very excited to also set some industry standards. We work closely with BCG, who is, I think, only endorsed Aptos to date as a letter one protocol, as well as others like Invesco, again, a trillion dollar asset manager, to publish white papers explaining the value of tokenized assets, which are very helpful for places like Hong Kong and others in the world to rely on these studies to really push the narrative that these kind of asset classes coming on board are really important and are going to be very transformational for our industry going forward. On the other side of the spectrum, we see emerging markets being a huge factor in this space. We're very excited to announce that PACT protocol is deployed on top of Aptos. It is a fully featured microfinancing program platform that allows loan origination, payments, warehousing, and security station fully on-chain. And this is a use case I think a lot of us are very, very passionate about. From my early days at Libra and Diem, a lot of it was about how do we support money movement in the emerging markets, that they don't have access to the same kind of financial infrastructure we have today. And a protocol like PACT is actually supporting this mission very clearly. They support loans. I think more than a billion dollars of loans have been issued on PACT as of now to lots of small denominations, whether it's $50, $100 loans, and those can be paid back at very fine granularity. It's been a very long project, I think more than nine months of incubation, but we're excited to see this kicking off. And many different retail partners are deploying loans on top of Aptos at very, very high rates. We expect this to grow drastically prior to the end of the year. Today, I think RWA to XYZ, we're already fourth. Just with what PACT has done, we expect to be first by the end of the year in terms of those assets. The last thing is we expect that this kind of finances available today in these emerging markets will evolve far beyond microfinancing. You start with microfinancing, you pay back those folks, and then those folks start to distribute that money around using the native currency, which allows blockchain and crypto to grow very, very rapidly in these regions where it's needed absolutely the most. Now, when we think about scale, Aptos is clearly the top here. One of the things we did recently is we ran a preview net with over 100 machines of our latest version of our software, and we wrote a benchmark showing that you could do 2 billion transactions in a single day. To put that into comparison points, Visa did 734 million transactions per day in 2023. MasterCard, 479 million. But what Aptos could do is actually support more transactions than all the credit card processors combined. And that kind of shows you that from a proof point, this technology is ready now. It's not something that's going to be coming in two years, five years, 10 years of line, or in 2030 with someone's very long-term roadmap. This is something that's achievable with existing technology now. The other thing is that you want to have a very fast user experience. When you look at the user latency, that is a time from when you kind of, say, load a website until that time is loaded. That's the thing we care about the most. Aptos is clearly the fastest here. 850 milliseconds for a transaction. Once you build up your wallet, you transfer money in Petra to another user. It happens in sub-second finality. Now, the average website takes about two and a half seconds to load. At under 850 milliseconds, that means you can insert many different blockchain calls without impacting that experience one bit. It means that every single user website, every single application, whether it's mobile or through web-based, can leverage blockchain without having to impact the user experience. And that's really, really important for mass scale adoption. And this is not something we do in experimental and just in the field. Back in August of last year, we saw Aptos run a record 326 million transactions on mainnet in a single day. And that's over 3,700 transactions per second, something that had never been achieved by any network before in the past. And with these numbers, what it showed you is the scale is runs in not just an experimental lab, but also in production today. Additionally, beyond that, it shows you that there was no failure rates and increases. There was no gasp increases. Everything worked perfectly fine. No users complained. No applications complained. And it showed you that even with very, very high load, the system could support that. So it's kind of time for those big players who've been waiting to deploy with crypto and with Web3 to deploy in Aptos because it shows you that, you know, you don't have to worry about the mission criticality of those operations not working when you need them absolutely the most. And it's not just us that's realizing this. We've been very happy to see the Electrical Capital Developer Report talking about some of the progress of the Aptos ecosystem growth over the last year. And right now, we are the second fastest Web3 growing ecosystem. We saw developer activity grow almost 100% from one quarter to the next. And over 1,000 new developers are choosing to build the future Web3 on Aptos. You know, a lot of people have wondered as well, the move is a new language. It's different than Solidity. It's different than, say, Solana's Rust. How will it pick up? And what we've seen from developers, and I encourage you to talk to as many as you can, move is a great language to build in. Once you start building a move, it's really hard to actually turn back to the old days. And the kind of reason for that is, for those of you who program, programming languages are something that I think has been overplayed a bit in terms of the difficulty from switching from one to the next. No programmer knows just a single language. Everyone knows at least three, four, or five different languages when it comes to writing code. And as you start to use these different languages, you understand the differences between one to the next. Move is something that was just built different. It's built for Web3 development specifically. It's built for the idea that if you make a bug and you make a mistake, you know it might cost somebody their entire life savings. Or it might cost, you know, a protocol like the, that might be the end of them going forward. It really reduces the idea that you can have bugs in your code. It won't make it perfect, but it makes it harder. And that's, I think, really, really important. And what we've seen is that as developers start to learn more about Move, they evangelize as well. They start to talk about the benefits of Move. And this is where we expect the development to grow to continue to happen as they start to play with the language. Let's go through the innovation stack a little bit. The first thing to start off with is Move 2. Move 2 is a new take on top of Move. We've learned a lot from the developers in the past of building, building on the platform. I think more than 10,000 modules have been deployed on top of Aptos today. Now, what's unique about that is that every single module that's been deployed on top of Aptos is open source code. It's compiled to Move by code. But there's a Move decompiler which allows you to reverse engineer that code and come back with the source of it. All that code that's been decompiled and resourced can then be put into, say, your favorite AI LLM model. You can use that model for actually training new developers to come in language. And I think this is where AI has really helped a lot of new developers to understand what Move can do as well as other programming languages in this space. Move 2 comes with so many different features. It is a fully complete developer platform. You have integrated specifications, formal verification, type inference, generics. Formal verification in a Move is really special. It comes with something called the Move Prover. The Move Prover allows you to write specifications into your program, which say, for example, you want to maintain the search in invariant. And that invariant could be a conservation of money. And it then will test every possible iteration of the inputs you have against the outputs. And so it's a very, very strong, powerful testing tool that no other platform has available to it except for within Move. But we've got all the things you would like to have for programming languages, higher order functions, memory safety, by-equal verification. And most importantly, this language is upgradable. So as you deploy your module, if you want to make a change to it, there's a way to do this where the code is kind of given to be API compatible. There's a lot of testing places put in place. And people can kind of see that history of lineage of that module evolving from time to time to time, which gives a very nice traceability around the history of that code. If you want to reverse engineering those code changes, you can also then use a decompiler to undo that and then understand exactly what changes were made from one version to the next going forward. So let's walk through some of the advantages from a programming perspective. We've thought a lot about how the syntax of the applications makes sense, how the functionality makes sense. And so here's just one example of a big change for us, which is the method syntax and the next location. So prior to the changes, we had to kind of explicitly borrow this mutable object. Going forward, you can use the .syntax location. This cuts the code down by a lot, makes it a lot simpler, makes it look a lot more like the kind of Rust-based applications you're used to developing in the past. Another one here is around enum types for versioning. So in the past, you kind of had these different structures. You set up data v1, you have data v2. And then in order to upgrade between these two paths, you kind of explicitly have to check the signer, the address. And this pattern itself is very unsafe, very complicated, easy to make mistakes on top of. In the new world, you can kind of specify this as enum as opposed to different structs. And this is very nice because then you can use the match statement like you would for any Rust code, for any enum, and kind of just operate the way you would expect to, depending on the different versions of that. Match is, of course, comprehensive. So it makes sure that you can't make that kind of mistake you could in the previous statement. The next thing we're going to talk about is the endgame of consensus. So one of the things that we have is a very strong research team. I think there are more than 25 PhDs on our team. And we have a lot of research we've done in the consensus space, which we use a lot of our time. So we started off, if you kind of go through the history, back in 1999, there was a protocol called PBFT that was invented, never implemented, but just invented and kind of research talked about. 20 years of research passed since then. And really, it's been very hard for people to kind of even improve upon PBFT. But we have a number of things, Jolting protocol, we have Narwhal and Tusk, which is a very exciting one, Bullshark, Shoal, Shoal++. Now the Narwhal, Tusk, Bullshark, and Shoal++, all types are around this, what we call DAG-based computing. So DAG is a distributed acyclical graph. It kind of requires each node to put together its consensus protocol from each node. And so from the Aptos viewpoint, back in 2023, you deployed something called QuorumStore. QuorumStore is almost like a multi-leader type system. Any node in the value or set can receive transactions. It's not a single leader. And each of those then broadcasts those transactions to other nodes, creating a proof of availability. This proof of availability is one of the key steps in terms of providing the data dissemination layer to scale out as many nodes and validators as you have. And the pipeline aspect of what Aptos has done provides a very unique infrastructure that kind of works very much like a modern-day Superscalar CPU. So in a modern Superscalar CPU, you kind of split up the phases of execution one by one by one. So you have instruction to fetch, decode, processing, maybe different ALU components, branch prediction, all that fun stuff. And those stages, you know, today it's maybe 20, 30 stages, allows your CPU to get very, very high frequencies. It's similar for us when you think about a processing pipeline for data infrastructure. And for us, it's the data dissemination phase, it's a consensus-based phase, parallel execution, parallel storage, as well as proof of certification. The end game of consensus though for us has been always in the database protocols. But going forward, we've got a new one coming called Raptor. And with Aptos already at the lowest latency possible in this space, Raptor will allow us to push the boundaries by even more, I think even by 15, 20%, especially in the cases in which nodes may not behave as best as possible. So we're very excited to see this technology being pushed to Aptos probably this year. Raptor is going to be a huge revolution and we expect it to live for probably the next 25 to 30 years in this space. Many blockchains have to think about scalability and Aptos as a leader in parallelization is moving as much of the resources you can into production from the scalability aspect. And so if you kind of go back in the history of blockchain infrastructure, you start off with kind of EVM and Bitcoin where you have sequential execution. Sequential execution means that you're operating and doing one transaction at a time. Even if your CPU has multiple threads, multiple cores, it's still just one CPU, one execution at a time. The next phase of iteration was around static parallelism. This is things that like Solana do. You declare all your dependencies up front and you leverage a scheduler to then operate on those types of dependencies and assume that all those conflicts are going to happen and then try to parallelize as much as possible. The third thing is where we built out. It's called dynamic parallelism around block STM. This has been a major shift in the way you think about programming for blockchains. It allows you to leverage as much parallelism as possible within your program without you, the programmer, having to specify a single thing in your code about what's parallelizable and what's not. So you can just kind of write your code like you normally would. Imagine you have a normal function you're writing today in Python. You can go ahead and access global state. You can, you know, leverage whatever you want to do without having to kind of declare it up front. And then under the covers, you have this very, very smart runtime scheduler, which looks at your transaction, runs it in parallel, tries to evaluate what dependencies are read and written, and then leverage that infrastructure towards scheduling as many threads as you can at the same time. And this has been something that is a technique used, pioneered by Aptos, but now used in networks like Say, Monad, Polygon, StarkNet, and being adopted widely across the industry. And so we're very excited to see that dynamic parallelism is something that is making its way throughout the blockchain space. But the question is, what's next? And the thing that we're excited to share is we're working on block STMv2. Block STMv2 is the next generation software transactional memory scheduler that will help us to get to many, many more cores going forward. And so the way that hardware is evolving right now is that you're seeing more cores per machine. You're seeing multiple sockets of cores per machine. And we expect this to be, you know, 256 cores, 5-inch-inch cores, even in 1K cores, to be pretty common on commodity hardware in the near future. And what that requires is a very new algorithm, how you think about the parallelization piece, how you can build the components of dynamic parallelism into a very scalable system for the new generation of hardware. And so block STMv2 is getting close to getting released. We're testing it right now. But the performance numbers are really, really promising. And we're pretty excited to share that this is going to be something that allows us to get even beyond the parallelism we have available today. ZapToss is a new features paper we kind of wrote recently. The idea is we really want to minimize the blockchain-based latency for every system, our part of the system. And so just going back again, we're talking about a paralyzed design. The design allows us to kind of do stage-by-stage optimization. ZapToss allows us to cut latency when you have very, very high throughput. So it's common today to see a situation where if you have very high throughput in the network, the latency goes up a lot. And the way we solve this problem is by taking those stages of execution we have and overlapping them as much as possible. So rather than executing sequentially, you can try to do as many as you can at the same time. And what that shows is that even at that very high 20,000 transactions per second, you can still do it very sub-second. And that's pretty exciting because as you think about what 20,000 transactions can support, that's more than Twitter, that's more than Facebook posts. And that scale allows you to really think about how a lot of the Web2 applications today can leverage blockchain into very core parts of their functionality. The way we do this is by taking those pipeline applications and then kind of shadowing the execution. The shadowing of execution that happens through the pipelining phase allows us to really compress the time into much shorter routes. And it's something that we're actually implementing today in the code. We expect this to be live and out to us mainnet in the coming months. The last piece I want to talk about is shardines. And shardines is the idea that, you know, today we have a very big shared state. That shared state allows us to all operate in the same kind of country. And that's really important because others take a different sharding approach. They shard the state in different pieces. And then they have bridges between those pieces. And that bridging between those pieces means it's very hard to compose applications that cross between each other. And we see this today in the L2 world for Ethereum, for example. Working between one L2 to the next, to the next, to the next across a bridge is a really poor user experience. And yes, it might get better over time as bridges get better or protocols get better. But by and large, it will never be a native experience. It will always be something that is going to be very, very different than operating within that kind of native L2 or that native state. And we really want to solve this problem by taking that same shared state and just expanding the pipe power behind it. How do we make that shared state operate in a sharded fashion? And the way we do that is not by sharding the state. We shard the validator itself. We take each validator and we start to break it up into multiple machines where each of those validators has many different execution shards going forward. The transactions themselves are then sent to the different shards. And you have a very fast, high-performing cluster within those validators, which processes chunks of these machinery, as well as then kind of does some storage updates, and finally passing by, aggregating the results, and putting them together. And what we've seen is that you can get more than 1 million transactions per second very easily. You can do more than 10 million transactions per second over time with scale. And you can do this by basically crossing off the dynamic partitioner and also a micro-bashing strategy. So we're very, very excited about the work that Shardines is doing. And we think it shows that blockchains today are going to be very different blockchains to the future. We're going to see blockchain scaling to all the biggest use cases out there. And if I want to leave you with a quote, Bill Gates had a very funny quote he made back in the day. He said, why would anyone need more than 640k of RAM going forward in the future? Imagine you had a million transactions per second and what they could do for you. Imagine the differences in the applications you could build, as well as the services that can be leveraged with blockchain. And that's what we're really, really excited about this going forward. So if we can wrap this up, I would say the focus points for us are around how do you support money movement at high velocity. There's aspects around trading, around stablecoin movements, around the RWA assets going forward. And then what is technology required to make that shift happen? That technology shift is going to happen in terms of pushing the boundaries in terms of the throughputs, the latency aspects, as well as the costs. And the more we can continue to do this and push this down, we're going to see very, very interesting products being built in this space going forward. And so with that, I think that concludes my talk. So thank you very much.