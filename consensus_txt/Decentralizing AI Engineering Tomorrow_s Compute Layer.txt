 Welcome everyone to decentralising AI, engineering tomorrow's compute layer. My name is Sylvia Toh, Director at Bullish Capital and joined by me are our esteemed panellists. We've got Lex from Generative Ventures, Ben from Jensen and Mo from ExoLabs. Now, AI systems are growing increasingly powerful and computationally intensive. So trying to cater for tomorrow's compute layer as well as AI infrastructure is becoming increasingly imperative. Now, I have here Mo who is looking at disrupting and being able to allow consumers to use edge computing devices like your everyday MacBooks to run compute. And Ben from Jensen allowing us to look at decentralised infrastructure from another lens. And Lex who is going to give us another lens from a VC perspective of how he looks at these crypto AI projects. The first question I'd like to ask is to Ben. Now, building towards decentralised infrastructure for AI training, that censorship resistance is so important for today's environment. Can you give us a little bit of insight as to why you think decentralised infrastructure is so imperative right now? Yeah, I think there's a few reasons why it makes sense. Some of them are a bit more kind of low level and straightforward. Like you can increase the scale of access to hardware by decentralising. You can reduce costs, things like that, that just make kind of financial sense in the world. But I think the kind of spirit of your question is, as you mentioned, more towards censorship and bias, etc., which is a bit more philosophical and social. The way we view it is, machine learning is a massively enabling technology. Essentially takes the entirety of the kind of knowledge world that we interact with day to day and replaces the base data types with this new rich data type of models and model parameters. And when you do that, you change the way people interact with just data about the world. So images, video, audio, text, everything that's digital is changed in a way where interaction is a lot more fluid and a lot more kind of human. You can take data about this room, for example, you can compress it into a space and then you can generate out new images of the room. You could generate video, audio that represents this room. You can generate text, you can tag it. You can do all of this just with electricity instead of using humans to do the kind of labelling effort. But when you do that, you put an enormous amount of trust in the system that does that. And so being able to create those systems becomes an enormous power advantage in the world. Our view is that the only kind of equitable way to do this in the world is to provide access to that technology to everyone. So everyone should be able to create the machines that do that compression of information and allow other people to access that information. If we allow a small number of companies to do that, we basically hand control over all of our interactions with the digital world to those companies. They can skew the information we read. They can skew the information that's collected about the world down the lines that they think is most important. Humans inherently do this. Companies inherently do this, like biases everywhere. Overall, our view on kind of alignment and censorship and bias is that all of that will exist in the world. The best way to make it aligned with the way humans operate and exist is to just allow everybody to reflect their biases in these systems instead of a small number. And in our view, the only way to do that is to decentralize the infrastructure underneath, make it a neutral layer and allow everyone access to those tools. So if you use a bunch of machine learning models and you say, hey, none of these models reflect my views. They're all biased to somebody else's views. You should be able to make your own and push that out into the world and maybe somebody else will like that model. So the future should be thousands, millions, billions of models that we're all interacting with and we're all able to create freely, not just like four models from large companies in the US deciding what we see and think and hear and experience when we interact with digital data. Yeah, the source of truth can be quite skewed and history is written by winners. So, yeah, the source of truth can be varied according to different lens. Now, Mo, when you say run AI clusters at home, can you walk us through what that looks like for someone using like their regular device like a MacBook Pro, say? Yeah, so generally right now if you want to use something like ChatGPT, there's a big model in OpenAI server somewhere and you have to send it a question and you get a response back. There's now you, many of you I assume have heard about models like DeepSeq. Like a really good open source model that you can download and use yourself. But the problem with something like DeepSeq is it's a massive model. Like the file just to download DeepSeq is like 671 billion parameter model. So it's like a huge file that you can just like run yourself. So if you're an individual or a researcher or a company and you care about, for example, your privacy. So you want to run the models yourself instead of relying on OpenAI and these companies, you have a challenge. You have to buy all these NVIDIA GPUs just to use these models or like customize it to your needs and so on. I work on a project called Exo, Exo Labs. You can go to our GitHub. And essentially with Exo, you can just grab some consumer devices you have. Like me and my co-founder both have a laptop. You download Exo in each and then you can just like run DeepSeq as if you're not going to be able to use it. You can just literally grab a few laptops together, download Exo and then with one click select DeepSeq. And then we would like split the model across these different devices in a way that you can officially run it at home. And one of the main use cases for that is like if you're a company like and you care about your privacy because of compliance reasons or a researcher who wants to do research on AI. You don't need to go and buy all these basically a mini data center for NVIDIA GPUs with maybe like half a million dollars. You can just get hardware you already have that you're using anyway like your laptops and you can just download that app on it and then just use that as if it's a small cluster. And that's what running AI at home means. And there's a lot of videos online about like running the biggest open source models like LAMA and DeepSeq and all these things. And you can also like do things like training which is less common for most consumers. You don't train models yourself. But like if you want as a researcher you can also use it to train models and so on. So it's essentially an easy alternative to like having a mini data center that you set up yourself. You just get consumer hardware you have and use it. And yeah, the high level idea is that you just split the workload across these different machines. Yeah, that's really revolutionary. So designing software that allows the everyday consumer to access their devices for compute. My next question is to Lex. So we know how much you love AI meme coins. And now there's as an investor, both of us come from the VC background. So what what kind of themes are you interested in within that crypto AI intersection? Yeah, so let me zoom out from that question and try to tackle kind of the underlying stuff that maybe is a bit unsaid. So I am a co-founder of a venture fund called Generative Ventures. We invest in a theme called the machine economy. So robots will generate most of our GDP growing forward and crypto is robot money. That's sort of the five year old version of our thesis. Five year old, you know, tell it to a five year old. And I think that it is really the only opportunity that crypto has to participate in real economic growth creation. Because we've generally failed to internalize economic activity from the real world. You know, like, yes, you can store Bitcoin and yes, you can do DeFi on Ethereum and then you can do other things on Solana. Anybody? Thank you. I got I got one laugh on that. You can tell how I feel about Solana today. But we were not out in the world, right? Real world assets are just tokenized BlackRock shares for whatever reason. That's worth 14 billion, even though we have 600 million of that out there. We are not yet payment processing. We are not in any merchants. We are not in any merchants. We nobody's built building real businesses outside of maybe 20 companies out there. Dow's are largely. Except the two that we've got on panel. Yeah, 18 outside of these guys. Dow's are largely a failure of coordination, right? They're not a future of the corporate form. They're quite challenged. And so we fail to penetrate or digitize the real world economy to date. And so that leaves me as an investor trying to think of, OK, what's a net positive thing that we can do in the industry as opposed to the complete self-destructive hellscape that was created by the people. How do I put it that enjoy scalping and extracting value from unsuspecting retail investors? What's an you know, like what's a productive thing that we can do? And the productive thing that we can do is say if GDP comes from software and hardware robots from machines, there's a digitally native economic infrastructure, and that is Web3. You've got ownership. You've got identity. You've got finance. You've got banking for businesses and banking for consumers. There's lots of super cool financial and economic infrastructure. And maybe just maybe we have this chance, you know, to create, to attach this modern financial infrastructure to the machines that could use it in a way that humans maybe can't. And we are profoundly fucking that up. I mean, you could not see a more profound failure on the part of the industry to actually go and get that done. And that's not of guys like that are on the stage here who are actually building really sophisticated technological products out there. Like there's nothing out there like Exo Labs, like nothing. He's the only one. He's the only one. And Jensen was so early to this idea, you know, driven by the philosophy and the sort of ideals that everybody in crypto represents and bringing it to the AI industry, which, you know, frankly, does not care at all and does not value privacy or any of the stuff that, you know, why we're here. So the people who are doing the hard things are being drowned by the people who are doing the easy short term thing, you know, and it's profoundly dispiriting. And I know I'm not answering your question very well. I'll get to it at the end. So, you know, everyone, everyone here who's in the audience, I encourage you, like, you probably came to this AI panel because you're like, well, what's what's left? Right? Like after Libra and Melania and Trump, like what's left? Right? Maybe there's a next thing. And so my my request of you is to, like, do the work and really find builders who are doing something novel and technical and who talk about customers and revenue and providing value rather than people who talk about FTV and unlocks and sniping and things like that. I'll answer your question in one one sentence. It's not going to be one sentence. I'm lying. So there's there's three categories in, let's say, crypto AI that we look at. And I think they're going to be in order of sort of size. The first category is AI is now the new distribution platform. So when mobile came out, it gave people an opportunity to have lots of new apps. You know, neobanks and pay tech apps and wallets and so on challenged banks. Right? And so conversational interfaces in AI are going to let you have access to various manufactured financial products, hopefully many of those in DeFi. And so the smallest opportunity is AI's distribution. Right? So you're talking to the blockchain. You're talking to smart contracts. There's a bunch of intense stuff going on and so on. That's interesting. But I think it's a small opportunity. The second and larger opportunity is rebuilding the AI supply chain using decentralized networks. And so that's, you know, we see everything in the traditional AI sector, crypto people trying to rebuild, whether it's decentralized compute, whether it is decentralized model training or data gathering or kind of going upstream and starting to develop capabilities and so on and so forth. That includes building agents. So I take issue with, you know, virtuals being an AI meme. Virtuals is not an AI meme. Fartcoin and Goatsy Maximus, those are AI memes. Right? Virtuals is a real company with lots of technology underneath it. But rebuilding the crypto economic version of AI is number two. BitTensor, Olaas, things like that. I think generally as the crypto world, we've had a pretty bad track record of rebuilding existing industries. Look at social media. Look at gaming. That stuff did not work out. And then I think the largest category, at least, that we're spending time on is really piping in the financial infrastructure of crypto into the economic activity of AI agents. So I think that's what crypto is good for. Payments, capital markets. And that's what we're focused on. Wonderful. All right. Well, that was a very long answer. I know. I took you on a journey. Nobody's smiling, which means you've all lost money on the media lines. I think most people are asleep right now, but time to wake up with a little bit more alpha. So Mo, I want to kind of ask a little bit more around the trade-off. So performance trade-off between running AI clusters at home versus like, you know, it's an edge device versus a cloud kind of computing device, which is different. So what? So the performance trade-offs between running AI clusters at home. Oh, yeah. So the short answer is that usually if you can't build your own data center, that's the best thing you can do. Like, if you can't just build a massive NVIDIA data center like Elon, then do that. Like, you'll probably get the best performance and everything else. What we think is more about is more like, well, is it cost effective to do so? Like, if I just care about running a model for my coding activity or for my company or so on, do I want to spend like $10 million just like building a mini data center? Yeah. And the awesome answer is no. Yeah. H100 chips are expensive. Yeah. Yeah. I saw a really interesting company here in Hong Kong that basically buys loads of old gaming GPUs and then racks them up into this massive box that you can buy for a few million dollars. I think I know that company. Which is like way more cost effective than like NVIDIA. So yeah, they're like, the short answer is in terms of performance, the best performance you can get is probably just like building a massive data center that's like really well provisioned and so on. But what we show is like you can get like almost the same performance, very close to that with like a fraction of the cost, without having to buy anything new. Like when I run DeepSeq at home, I didn't buy anything. I just had the laptops I already have, like my old laptop, my current laptop, my co-founder's laptop, and that's enough to just run a model. And we didn't have to spend any money on it and we get like pretty nice performance. It's not as good again as setting up like a $10 billion data center, but it's good enough for most things. That's a short answer. Yeah, definitely. So I mean, it's not necessarily true that it's chip availability is out there for everyone as well. So being able to run consumer grade software at home is kind of empowering your- It's like the difference between buying loads of hardware and downloading an app. It's just the easiest like drastic. Yeah. Are you guys ready for, you know, if someone in the audience today wanted to try out EXO, is that- Yeah, you can try it already. Like you can just go to the GitHub one click. There's also a desktop app right now. So if you just want to write code and just like try the app, it should- There's the alpha version of it out. Yeah, you guys should definitely try it out if you haven't already. And if you're a company, you want to try it properly, just reach out to us and we'll love to onboard you. EXO labs. All right. This one's for everyone here. So value accrual, do you see it going more towards inference or is it training? Maybe Ben? Yeah, I can jump in on that. I think we've been reasonably outspoken on this for a while, but like in general, I think focusing on inference versus training just doesn't make that much sense to us. Because at the end of the day, you need both of those things within machine learning. We've kind of long said that basically the two will blur. And I think with the like deep seek R1, like reinforcement learning, the supervised fine tuning stuff that you see happening, it basically is happening. The inference and training blur together. We think at a kind of lower level, at the end of the day, if you think of machine learning as changing the data representations that humans interact with, like I said a little bit earlier, you can think about essentially just reading and writing to model parameter space. Right now, you would read and write to the internet. So on social media, everyone here can put updates. You can put images onto your Facebook page or something like that. You can write like updates to everybody. You can also read everybody else's and you're just constantly interacting with this rich system of data that's shared between everybody else in the world. But the crucial part is you're constantly interacting. You're not just sitting there and consuming information. And I think when people talk about like always inference more important or is training more important, they typically side on one of those sides where people will make a mistake that happened with the early internet where a lot of people thought the early internet would be basically read only for most people. There would be a small number of organizations that would put information up there and everybody else would just have this terminal where they'd read that information. It'd be like a kind of like source of news for them, but they wouldn't interact with it. And very quickly, we got this desire from the entire world to actually put data online. Like Geocities came around. Everybody wanted to make their own website. Social media absolutely exploded because everybody wants to write to the like shared human knowledge base as well as read from it. And so we view machine learning in the same way. Basically, everybody wants to read and write from this shared knowledge base. That is kind of training and inference blurring together to happen all the time. The issue and the reason it's separated is just like kind of historical reasons within how you do machine learning. Training is a slightly harder task. It involves roughly like 3x computers inference. So a smaller number of people would do it. It's been harder to do historically. But as we come to productize machine learning more, the ability to do that training and actually update the parameters of a model can spread out and be available to more people. So I think we'll definitely continue to see it blurring. But there'll be certain companies who are incentivized to say actually the only thing that matters is inference. You just need to kind of talk to models. You can kind of hide the writing portion that you do in other areas of the apps and things like that. But ultimately to us, it's just read and write and everybody is going to be doing that. What do you expect the user persona or like the user behavior to be for the writing part? Right? Because like there's a handful of people in the world who are competent at what you describe. And putting up like a Geocities or like a tweet or a TikTok video, like that behavior requires one push of one button really? Yep. So how do you see people actually doing that behavior? And then what are maybe like, do you have any personas in mind of like, do you have to be a Math Olympia winner to do this or? I think it's productization. So you think Geocities, it wasn't just click a button. It was like, you're going to have to write HTML. You're going to have to like learn how to do this thing. And then obviously social media came in and made it literally just a text box. It was like, okay, people want to do this. Let's just productize away the hard aspects. But it did start with those enthusiasts. And I think we'll get that same progression here. It starts with a bit more effort required in order to do it. It's a bit harder to do with the tools. But then through time, we productize around the incentives of the market. And when I say incentives, I don't mean anything to do with crypto. I mean, just let the way people want to interact with tools be the thing that dictates the kind of progression of those tools, which is just how tech works, right? Like a company will see an edge. They'll exploit that edge from like the desire of users. And then through time, we'll get better and better products. And so I think we'll see personalization as the main aspect that drives that writing. So people will want a model when they interact with it that knows slightly more about them. They're just like, okay, when I interact with this model and it has a bit more information about me, it's actually better for me. It gives me better answers. And then through time, that gets deeper and deeper and deeper. And if you look at machine learning over a longer time horizon than like a few months or a year, and you say, we're all going to be interacting with models in the future constantly, which I think we are. Through time, those models are really going to have to index to us personally. And then if you look over like generational timelines, you're going to have models which learn based on information about a person through their entire life. We generate enormous amounts of data. The sensors on our phones, on our like smart watches, all the devices we have around us are generating data about us and about our environment that's very rich for our interaction. But currently, we can't ingest it in any way. So you can't use the fact that you have a camera on you all of the time to enrich your interaction with technology too much because it's just too expensive for you to get the phone out and take images and then tag them and things like that. But what machine learning does is give us this electricity driven way to ingest all of that information into a parameter space where it can actually be used to help us. So I think we'll see that. We'll see just people having all of the information about them be compressed into these models. And then where that goes in terms of the rest of the world is TBD to an extent. A few ideas could be you could have a version of the internet where every website is just a model where people can put information into that model about a certain topic that they know more about than everybody else. And then that model exists autonomously out in the world and can be linked up with other models. Exactly the same as how the early internet existed. If you knew a load of information about a certain type of tree, you're an enthusiast about that tree, you could make a website about that tree and every so often somebody would find it who's interested in that tree and would be like, Oh, cool. I got this information. I think the same thing can exist with machine learning. It's just a richer data type. Yeah, I think the label that we and a bunch of the industry kind of put on it as agents, whether people like that word or not. Right there, there is a productization and shape to it, which is the the agentic economy. I know we're out of time and I just want to kind of say one thing, which is like financial nihilism is not cool. Just because some things are meaningless and bad does not mean all things are meaningless and bad. And if you are older than four year olds, you know, generally you should be able to follow that logic, you know, so nothing cool or true about financial nihilism. Just because there is a bunch of crypto. A.I. grift does not mean that all crypto. A.I. is a grift. There are people who are literally doing hard things. They could be right. They could be wrong. Maybe people don't want to run giant models on a refrigerator rack of phones. Maybe people don't want there to be a billion websites full of, you know, machine learning trading, but maybe they do. So we need the people who are crazy enough to try this stuff to feel safe and empowered to do this innovation. All right. So please don't confuse that together. We've got 30 seconds on the clock. Just quickly. One last question. Now, do you think crypto decentralized A.I., whether it be inference or training, is going to come within crypto or is it going to be outside? Just outside? I think it's a combination. I think both sides have a kind of difficulty with applying it. I think crypto has the issue that people get excited about the shiny returns within like six months. It distracts everyone from the real technology. It takes builders out of the space because they get into generational wealth within like six months and they're like, what am I even building now? Like, oh, I disappear. And then the A.I. space is far too cynical about crypto as a technology because of the kind of crypto side, which does that big shiny like fast returns, no real substance behind anything. But it doesn't matter because everyone's got rich. So like I think both sides need to essentially come to terms with each other. What I would encourage is the crypto side to think much more long term than it currently does and think about actually creating change in the world rather than just returns. And the A.I. side to stop being so cynical about crypto, dig into the real technology and ignore the like shiny veneer of everybody getting rich and some people getting rich and some people not. And actually look at the technology itself, particularly the ability to establish trust in a completely open and scalable world. And hopefully then we just get the confluence together. I don't think it'll come from one particular side. I think it'll just come from both. All right. Well, that's all for today. And if you guys haven't checked out XO Labs, GitHub, they've got 27,000 stars. What a milestone. Jensen, thank you very much. Ben and Lex from Generative Ventures. Thank you.