 Scott DeRue, Founder of Lidl, Founder of Lidl, Founder of Lidl, Founder of Lidl, Founder of Lidl. Found a good spot. Okay, hey everybody. My name's Scott. I'm the co-founder of a layer one blockchain called Kava. And today we're going to talk about how Kava has launched the world's largest decentralized AI model, which actually happened this week at Consensus HK. So we'll be going through like a high level of what Kava is and what Kava's been over the last six years. We'll talk about AI, so centralized AI, how decentralized AI in the past few months is starting to reshape or redraw the power map for AI usage. And then we'll talk about what Kava's launched and how it's participating in the overall DAI ecosystem. So just a brief intro of Kava. So Kava is a layer one blockchain that was launched in Q4 of 2019 on Binance. It was the Binance Launchpad Project of the Year in 2020. And it really started with creating DeFi products in the Cosmos ecosystem before a lot of DeFi products were built outside of the very famous ones on Ethereum. And so it ran that for a while and then in 2022 launched an EVM, onboarded a bunch of developers, users and community around that, and then hooked up the Cosmos ecosystem and the various Ethereum EVMs through its interoperable technology. The AI stuff that's being built this year in 2025 is really building on the success of what Kava's had in the DeFi space. And due to its unique position between the, at the interface of the Cosmos ecosystem, or intersection of the Cosmos ecosystem and the Ethereum ecosystem, it's been able to secure massive partnerships like exclusive Tether partnership, WBTC, BitGo's WBTC, and deep integrations with exchanges like Binance, Coinbase, Upbit, and every other major exchange in the world. Some of the things that Kava has done over the last years, so it has an exclusive Tether partnership. Kava is the distribution channel of USDT to the Cosmos. If you have any sort of USDT on Cosmos, that's being generated on Kava. And there's a little under 200 million USDT issued on the chain today. It has a large ecosystem of DAPs that have been deployed on the EVM side. A large liquid community pool that's used by the Kava governance holders. It's one of three chains that has a native USDT and WBTC integration. It's because it started in the early days with interoperable technology at its core. It's processed safely over $2.5 billion in cross-chain transactions. It's got a bunch of assets on chain, low transaction costs, and a unique seamless cross-chain architecture between the Cosmos ecosystem and the EVM. Yeah, and as a result, it has a large and growing ecosystem of developers, users, and community members, as I said, with integrations with pretty much every major thing in the ecosystem. And so now, a big thing that Kava and a lot of projects are focused on in this year is moving into AI and using this powerful technology of AI as a thing that can help in Web3. So I'm just going to give a brief overview of what centralized AI looks like so we have a better picture of how decentralized AI stands in reference to that. So traditional AI has three main layers. Application, like a cloud or on-prem layer, and a hardware layer. So the application layer is things that you guys have heard of, like ChatGPT, DeepSeq, Anthropics, Cloud, and XAI. Cloud layer is where the actual GPUs are hosted to train these models that are ultimately served to users. So that's Google Cloud, AWS, Azure, and then there's some startups like CoreWeave Lambda. And then the actual hardware providers themselves, NVIDIA, AMD, and a number of other ones. The application layer, we're basically just training up models using techniques like reinforcement learning and then applying those models to front ends like ChatGPT, DeepSeq, whatever. And the very interesting thing here is if you were in AI 10 years ago, you could see how it was useful, but the models weren't big enough to actually power any kind of real mass adoption or usage. And one way to view this is by the parameter count, so how many parameters there are in a model. And we can see since just 2018, we've gone from like sub-1 billion param models to upwards of close to a trillion, with 800 billion parameter models being pretty typical and pretty common, and even like 80 billion parameter models being pretty useful. And the interesting thing here is that kind of the bigger the models get, it seems, the more intelligent the result is. And there doesn't seem to be a hard cap on how many parameters a model can have as long as there's sufficient compute and data. And so, you know, the end output of like, okay, you can have a really big model, but what is that getting me? There's a bunch of the world's largest companies and startups alike racing to build the most powerful LLMs, and one way to measure that is to benchmark that against a number of different benchmarks in things like math, human language processing, and code generation. And these are just some like recent benchmarks here. Okay, so that's the application layer, and then just quickly the cloud layer. So basically, you have these massive data centers, you wire up GPUs using high, low latency, high throughput cabling to create effectively one large GPU, one massive GPU that can train these models. The bigger that aggregated massive GPU, the shorter time it takes to train a very large parameter model. And then the hardware itself is growing at an exponential rate. So you can see in terms of TFLOPs that in 2016 to the black walls that were released, that we have something like a thousand in thousand X increase in the AI compute power, and that still is likely to go up. So you have a situation where the models are getting very, very big. The computers that support the training of the models are themselves getting faster. And as a result, we're seeing rapid advancements in better and better AI that comes out. It doesn't really seem to be an upper bound in that. And we're seeing that AI is likely going to come to every industry, including blockchains. What's interesting is that in the last two months, like in the research community, it was pretty clear that it probably isn't the case that you need to be a monolithic Microsoft with Azure cloud infrastructure to be able to support a company like OpenAI. But the market hadn't priced that in. And about a month ago with something like DeepSeap coming out, the market was able to price in that actually at a fraction of the cost. And without like, you know, like like wizard level PhD, AI researchers, you can actually produce very compelling models, as I mentioned, at a fraction of the cost. And so now there is a credible belief in the market that open source and to it and then taken to a further extent, decentralized AI can redraw the power map for AI moving from this sort of like closed source, high cost hegemony to this being able to actually produce and deployed on a public utility like a blockchain. So we're going to quickly go over what it means to be decentralized AI. It's worth noting that we're in like the pre-DeFi days where there's a bunch of projects that are working on things, but they're not talking in the same way and coordinated sort of like the proto-DeFi to DeFi days. And so we're using this idea of DAI to stand for decentralized AI. And we'll give an overview of what that can look like. So DAI similarly has three stacks. So there's an AI dap and agent layer. There's a D model layer where open source AI models that are community trained, transparent, weights and source code can replace these kind of like black box models. And then a dpin layer, which is a decentralized network of HPC resources like GPUs that can enable distributed training and hosting. What's kind of interesting is that DAI is the convergence of two tech revolutions. So this kind of Web3 blockchain technology and AI itself. And it's important to note that DAI can really reshape how intelligence as a service is built, shared and governed. And it merges the permissionless infrastructure of a blockchain. That's where you're going to host the thing. Collaborative training of open source AI models. I think that that didn't have a lot of weight mid 2024. But now when we see something like DeepSeq and then a number of projects building on top of that, all of that built from the open source stuff that Facebook put out with Llama. There's real power and real traction from a market's perspective on open source development of this stuff in producing real tangible powerful AI that can be used as a service. And then aligning incentives through tokenization of these things in an aligned way. And it's worth noting that the landscape is expanding. There's a ton of AI projects, crypto AI or DAI projects that are out right now. This is just like a cross section of some of the ones that have brought to market some real tangible achievable palpable technology. But there's plenty of stuff going and it continues to grow in each one of these layers. The AI agent layer, the demodel layer and the compute deep end layer. So now going into specifically like Kava AI and where we fit in the overall broad DAI landscape. It's likely not going to be the case that it's going to be monolithic. And one project is going to own the deep end cloud compute or deep end models and agents. You're going to have agent application layers. You're going to have best in class models and you're going to have best in class deep end. And it's probably not going to be the same. Kava is focused on the model layer. And it's building decentralized AI which can then host things like AI marketplaces that can hook into the rails that Kava already has across different ecosystems to be able to move that data cross chain. And so Kava is taking a pragmatic approach. You can liken it to creating a decentralized deep seek in 2025. You started with closed weight models like Anthropic and OpenAI. Now we have open source open weight models that are very popular like deep seek. But your information is still going to a database that's held by a company that very likely will be accessed by the CCP in the future. What Kava is trying to create is a similar type of setup where you have a model that's run on a cloud infrastructure like Akash. It's trained open source and open weight. So just like a smart contract, you can inspect the code and the input and the output is what you're expected. And the model can't be trained to tune parameters to serve you better advertisements or something that you want. And then it's done. It's developed in an open and collaborative way. Oh shit, I'm running out of time. So just at a high view, this week we launched, you can go check it out at chat.kava.io. There's a simple chat interface with two different models, a general reasoning model and a blockchain instruct model. It looks and feels like chat GPT or Deep Seek. And you can go interact with the general reasoning model and it feels just about as good as Deep Seek or O1. And you can use the blockchain instruct model to hook up your MetaMask, call balance on your Kava, send coins, and then eventually we're going to open that up to other ecosystems such that you can call your balance on BSC, base, Solana, and be able to move those funds at an abstraction layer. I'm running out of time, so I'll just finish with this kind of point here. So what we've launched this week are basically two models. In the future, they'll get merged into one. But one is this general reasoning model that is approximately as good as a Deep Seek R1, like quantized model. The vision there is that users can show up, interact with the general intelligence, and have all of that data be stored in browser where they can control it, remove it as they want. The models are open source, open weights, and it's hosted on a blockchain. And we're going to try and grow as much usage as we can around that product. And then the other product, which is an abstraction layer to all the different Web3 services that you might use, you can type into the thing, you can talk into the thing, produces human language, and maps that to tool calls that allow you to send coins, stake, borrow, whatever transaction you might want to do cross-chain. And the end vision of that is that you can just talk at a thing, and it'll execute the things for you. And you can either sign with your MetaMask or if it's a hot wallet, just execute it straight away. I'm out of time, that went fast. So at a high level, Kava is pushing through the end of Q2 2024, releasing the world's largest decentralized model today. We're going to continue building that. I encourage you guys to check it out at chat.kava.io. And you can follow us on Twitter at KavaChain. Thanks, guys.