 It's fantastic to be here. And we have almost everybody that we're supposed to. I think we're going to have Philip join us pretty soon. But first, I want to thank our panelists for being here. We've got Mark from Nier, Anna from Open Data Labs, which is the company behind Vana, and of course, Magnus from Blocksense. And I guess anybody who's got an NFT profile is just sort of like an abstract instantiation of a concept of a human being. I'm Lex. I'm a partner at Generative Ventures. We invest in crypto AI, machine economy, and Deepen. So I'm really excited about this conversation. We're going to focus on the data layer in crypto AI and much more broadly. But maybe we'll just start with introductions. So Mark, what's Nier? And what do you do there? Hello, everyone. My name is Mark Mee. I'm the head of partner development, VC, and investment relations. Nier is the blockchain for AI. So we started out as a blockchain layer, a highly scalable focus on sharding layer one. And now one of the most active with currently 37 million monthly active users. And moving with the chain extraction to really unify the liquidity as well as all of the chains together. And lastly is the long-term vision of really connecting everyone and allowing them to be user-owned and controlled AI. Right. And we'd love to kind of discuss more on how data really focus upon that. Within my role, I kind of lead a lot of our partner development and talking with various verticals within partnerships, as well as kind of our VC and investment side, as well as our whole VC network. So really connect with all the VCs like yourself and what is coming up within our ecosystem, as well as from the protocol and Nier itself from that perspective. Great. Thank you. I feel very connected right now. Well done. Anna. Yeah. I'm Anna from VANA. So VANA is, from a technical perspective, it's like an L1 that can work with private data. Usually blockchains don't really work well with private data because then it's public and then you can't charge money for it or kind of permissionlessly or permission access. In terms of the goal of VANA, it's really about building a self-sovereign data ecosystem where users own their data, can bring it with them across applications, can grant access to train AI models on it, and where developers can access really high-quality data sets. Because a lot of the data that you need to train AI on today is sitting inside walled gardens of big tech and not necessarily available. You might know VANA through different data DAOs that exist on the platform. So there's like the Reddit data DAO, there's a LinkedIn data DAO, a Twitter data DAO. All of these different projects are essentially onboarding data in an interoperable way to VANA and allowing for AI researchers to essentially train models across these different data sets. Awesome. Magnus. Hey, everybody. Magnus from Blocksense. We're a decentralized Oracle network. We just came out of A16Z's crypto accelerator last fall and are currently on 30-plus EVM networks with the first mainnet launches coming imminently. So what we do, what makes us a little different, so we're actually a programmable Oracle network. We're secured through ZK roll-up architecture as well as shared security through restaking and a modular programmable SDK. What that all means, what all that jargon kind of means together, is that we enable any builder to bring any kind of real-world data or even compute on-chain in a verifiable way. So moving beyond purely just like DeFi price feeds all the way to things like AI compute, like GPU, even CPU tasks, all of that can be kind of permissionlessly brought on-chain with the verifiability brought on by the ZK architecture. I feel like we've minted the NFT. That was great timing, by the way. Yeah, yeah, it's great. You're just in time. We're all friends already. Philip, what do you do? And what's your project about? Sure. Pleasure. Thanks for having us. And sorry for the multiple delay. I'm co-founder and CEO of Cookie Free and contributor to the Cookie ecosystem. We are building a data layer for AI, LLMs, agents, as well as businesses. So you can think of us as an aggregation engine for sourcing the data from both off-chain world and on-chain world for either business intelligence that helps companies to optimize their spendings to actually understand their users from where they are coming from, what are the conversion events they are conducting, what is the overall business situation from the data standpoint, as well as for the investors. We are providing insights, like kind of an alpha, intersecting social data like Mindshare as well as on-chain. So we are the creators of Cookie.fun, among other products, which is the probably biggest distribution channel for discovering AI agent tokens. So yeah, happy to join the discussion. Fantastic. So we've got 40 minutes, which means we're going to go real slow and basic across everything. And, you know, everybody mentioned the word data and said words about the word data and sort of like the words all kind of sound the same. But at the same time, the projects are all really different. Like there's completely different value chains and different things that you do. So can we disambiguate the word data in the first place and then maybe we can split out like financial and behavioral and like different industry sectors that you focus on because otherwise it's all a bit of a clump. So, Anna, maybe we start with you because like let's say I'm Sam Altman, you know, that's, you went to Y Combinator. I don't know if that's how Sam Altman runs Y Combinator. Don't you just like download the internet? With some bots and then you have all the data? Like what is data? What are you actually talking about? Yeah, great question. So you're kind of right in terms of how it works today. Like you basically just take the whole public internet, all the data that's publicly available. It's like an NFT, right? Click save as. Maybe. I'm not sure. Yeah. I think that, yeah, so you can look at all the data that's publicly available today. The data set, there's like common crawl and then there's a higher quality subset of it called FineWeb. That data set is around 15 trillion words, which is a huge amount of information, right? I don't know if humans ever like consume that much, but the leading AI models are now trained on that much data, right? So like Lama 3 is trained on 15 trillion words. If we want to make AI better and continue to scale it, we need to find a place to get more data. So I guess to your question directly, yes, you can try to download the whole public internet, but we've already done that as an AI industry. And so then the question becomes, where do you get more data, right? And a lot of that data is sitting inside of the walled gardens of big tech, right? So a lot of the data, say, sits on like Twitter, which you can't necessarily scrape. Maybe there are ways of scraping it. Google Docs data, right? Your email data, your iMessage data. So the way that big tech companies today and kind of leading AI labs get this data is they typically buy it from data collection companies or directly from companies, right? So Reddit earns $200 million selling data directly for AI training. And then there's this big industry that's relatively quiet, which is called kind of data collection. Appin is one of the big players. My co-founder used to work there kind of selling data to big tech. And some of the leading big tech companies have like hundreds of millions or even a billion dollar contract buying a ton of data. What they do is essentially a company comes in and says, hey, I want to buy iMessage data. Apple's not going to sell iMessage data. So then this company is like, okay, I'm going to go find 10,000 people who will export their iMessage data, put it into this pool, and then I can sell it back to that company. So yeah, I guess that is kind of how data markets work today. But like, if you've got a trillion, gazillion words already on the internet, like isn't it a drop in the bucket what I have in my Google Docs? Like why does the, why care? Why does it even matter to get this like private stuff when you've got all so much already? Yeah. So if you look at the ratio of how much of the public internet, how much of the internet is publicly scrapeable, it's actually less than 0.1%. So all of that public stuff represents an extremely like small portion of the overall data. And if you want to make AI models better and kind of continue the scaling law with both compute and data, you need some place to get that data. There are other approaches you can try to take, right? So like synthetic data is one workaround that people have been trying. Because it's so hard and expensive to get the data, right? So DeepSeek did this where what they did is instead of getting a ton of data, they started with a smaller amount of really high quality data. They actually hired a bunch of like PhDs to generate like math equations and coding and stuff like that and use that to then generate synthetic data. But that only works to some extent, right? From an AI perspective, the ideal case is like you could query any data from all these different walled gardens. So it's extremely high quality and there's a ton of it available. But that's very hard to do in practice, right? And so, and the incentives aren't really designed that way because of the walled gardens. Yep. I think that's a super valuable thing to open up and I appreciate it. I guess question to Philippe and Magnus. what's the difference between that, meaning the entire internet and all of your personal text messages, and the types of data that you're working with? Like, are we gonna shove Reddit into a verifiable TE Oracle? You know, are you selling to enterprises TikTok comments? Like, what kind of data are you working on? Yeah, I could start there. Like, so I'll just zoom out a second. I wanna take a little bit of issue with the title of this panel, which is data is the new oil, right? I think it's a somewhat hackneyed phrase that people have been saying since probably the 90s. If it is oil, it's not new, but it also is not oil, right? It's not a commodity. Also, it's not data, and this isn't a panel. It's a hallucination. Reality is fake. Don't buy mean points. You knew where I was going, didn't you? No, so data is not a commodity. There's lots of different types of data. Even when it comes to personal data, you have self-attested personal data, which has a certain level of reliability. Then you have third-party attested data. It could be signed. It could not be signed, right? You know, to call data oil, I think, is a little bit of a misnomer. But at Block Sense, you know, so we're kind of opening it up to builders to decide what sort of data needs to be on-chain. And for sure, not all types of data should be on-chain, right? When you're talking about personally identifiable information, bank account details, things like that, it's actually illegal to put that on-chain, right? It breaks GDPR. But just looking, you know, taking a step back and looking where the demand is that we see for oracles, like data oracles today, it's pretty much all in DeFi, right? That's sort of 99.9% of the use or usefulness of data on-chain today is for your lending protocols, for your perpetuals, DEXs, for your prediction markets, right? Now, that's essentially like a lot of work that gets done to bring some information on-chain that's actually available for free via APIs, right? The CoinMarketCap or CoinGecko APIs are freely available, but, you know, chains are willing to pay, you know, like six figures, sometimes up to millions of dollars to actually get this data on-chain. It shows you some of the difficulty that is involved with actually bringing that freely available information on-chain in a trust-minimized way, right? So it's all the kind of operating costs and so on. I think, like, as an industry, that is sort of where we are today, and some of that rent-seeking behavior really has to stop, and Bloxens is trying to enable that by not charging integration fees and the like. But what I would really like to see is much more diversity of use cases and applications on-chain that require data, right? So this is where you're kind of, like, decentralized compute, but not even just computation, things like, you know, like weather data, right? So if you have on-chain insurance, this is actually one of our ecosystem projects is building this out. It's like, you know, can you settle insurance claims for the agriculture sector using weather data? You know, did it rain? Was there a drought? This sort of thing. You know, that's just, like, one very narrow use case, but I think it paints the picture of, you know, like, how we can go beyond just price feeds being sort of what oracles provide and actually, like, expanding the pie. Yeah, so quite two different and distinct things that data there means. I think there's actually an interesting analogy. So, you know, in the case of Vana, it's about as much unstructured data as possible in order to put it into, you know, a training process to create AI models, right? So, like, there's a big math box and you're trying to shove data in it, but the data that you're trying to shove is basically the exhaust of all human experience, structured, unstructured, everything. One note, data on Vana is structured by the data DAO and verified. Just one thing. So, yeah, you do need the structure so that you understand kind of the quality and what you're consuming, but the general principle. Yes, but, like, text you can pull in, right? Yeah. Whereas in the other case, the amount of data is maybe one millionth or one trillionth the amount that you would go in the AI world, and it's quantitative, it's deterministic, right? And it gets fed into the financial infrastructure of crypto in order to do computation and then structure DeFi products. So you have almost, there's an analogy there that, like, the ingestion mechanism is actually quite difficult and expensive. So let's switch to Mark and Philip. Maybe, like, now that we're talking about what kinds of things you can bring on-chain, what's the next step, like, in the value generation or the supply chain of the sector? Like, okay, now we've sucked in some structured data. We've sucked in qualitative stuff for these different use cases. Like, what do you see actually happening on-chain with it? So I actually think this is where this data is a new oil, kind of what you were talking about in terms of the statement. I think it's quite interesting, right? Because if you actually break down what oil actually means or what it has been utilized as... It's dinosaur juice. Exactly, right? Well, I mean, outside of it, you go to the next steps, and then you can process it, or it could be utilized for machinery, utilized to power vehicles, obviously, for heat, right? I mean, and so to me, that's exactly what they have just been describing in terms of the different use cases and applications and depending on how they modify or work through that oil, right? To make that work. And here it's the data, right? And so I would say Nier for us is really then focus on maybe the connective tissue to utilize it from the earlier stage, then processing of executing transactions, cross-chain transactions, and helps of executing and utilizing the oracles to make different swaps and trades. So one interesting product that we recently launched was called Nier Intense, which enables basically cross-chain swaps natively, and it's done in a way where it allows access to previous maybe not accessible assets, such as Bitcoin, Ripple, Doge. We were able to integrate BearChain on the first day when they launched, and you're able to swap between your Nier or Solana or ETH or anything like that to power that, right? And it's utilizing feeds, it's utilizing the data from that, but then you're able to execute on that point. And so I think that's one aspect of kind of our chain attraction point, but in the future, in terms of the user-owned and controlled AI side, I think it's really important to have the right models, right? Which all of these, you know, they're feeding that to really build. You're constantly training to figure out where to utilize these swaps and models, I think, which is kind of what Philip was mentioning in terms of being that dashboard and highlighting the different types of agents to utilize from that standpoint. So I guess short in terms of the data aspect, it's really wide and spread depending on the use case and the specific points of action. It could be very niche, it could be very general. Yeah. And so one aspect that we're working on, for example, is kind of a, you know, AI assistant, right? To help you execute specific actions, and it could just, it doesn't need to be within Web3 or crypto, but it could be something from your fiat on-ramp to buy something from Amazon or, you know, that's the vision that we all think will happen in the future, right? Comparing your Web2 side to our future Web3 side, right? Or the future agent-to-agent execution side. So I think there's a lot of direction that we can really bring this discussion, but I guess it really depends on what's most exciting and what's applicable to maybe the panel as well as the crowd. Yeah, I think you're being a bit modest. I think Nier has been fantastic in kind of investing across the supply chain in crypto AI, in addition to sort of these more structured trading examples that you've talked about. So on Cookie and where you sit, I think it's really, you touch both sides, right? In the sense that you have products that are like quantitative information analytics products, right? That are sort of like in the Oracle world, and then you're also tracking these agents which are largely built on large language models, right? Which are what we talked about, the thing that you train with the download of the internet. Can you talk a bit about maybe just the recent history of like how you saw the rise of these conversational AI agents and how you started thinking about tracking them and like the financialization that happened over the last six months? Yeah, sure. So I would say like the AI agents is nothing new, specifically like in Web2 at least. It's something new that we discovered in this like crypto bubble recently. So like giants that are in this like traditional markets are building and working with agents for months or even probably already years. And I think this is good that we discovered it finally in crypto and it kicked off some small trend, hopefully a long-term one. But I think like obviously it's very exciting that we have this intersection of blockchain execution and AI agents that can be autonomous and can do transactions for humans. My personal view on that is that this is this ultimate UX layer that is required for this legendary adoption, mainstream adoption to happen in crypto because like blockchain is not designed to be used by humans. It is designed to be used by the agents that will execute the transactions for the humans. Like it's too complicated for us to double check every transaction, pay the gas fee, double check every smart contract we'd like to interact with, cross breach, understand what's going, like understand the backend. Right now the web tree is the UX layer is that you are interacting directly with the backend. Whereas agents are providing finally the possibility of actually not taking care about anything what's happening on backend but just like clicking the button, making the, letting the agent do something for you. and this goes for both, applies for the intelligence layer. So like the idea what you would like to actually execute on chain and then the execution itself. So I would say the thing that we are right now looking at with the big excitement is that we believe that those data that we are right now processing are still to be processed because as an example, if you are having any like data sets of on-chain and off-chain transactions, you can, let's say, calculate the mind share on the social side and on the on-chain side you can calculate the volumes and market caps. And even this simple ratio like mind share versus market cap gives us a lot of alpha from which all of like our users are using on a daily basis. And only if you label specific tokens with this ratio then LLM can actually utilize it because without calculating it, labeling specific entity with this outcome, it's like impossible with this computing power to like process everything every time. So I think like we need a lot a lot of like labeling so process data that can be understandable for LLMs so just to like make it more straightforward for the LLM to connect the dots and find for example correlations they have to work with the process data not the raw data and I think this is what we need to do in terms of like big effort to be done still and what's exciting about that is that not only humans will be coming up with the ideas of those labels but also the agents themselves they can come up with some idea okay maybe let's find the smart money that was very early with AI agents let's compare it to some other moves on chain and let's start labeling those wallets let's see what is the correlation with some social sentiment that was around that and so on and so forth I think there are like plenty of things that are still to be discovered from this like digging deeper and deeper right now the computing power actually limits us in that terms but labels make this like easier for LLMs to process that and like I'm talking about labels as an example of course but this is how we are right now looking at it we think that there are like there is a much more alpha to be discovered still we don't we do not know nothing right now comparing to what we will know probably in a few years once those data will be processed and we will discover so many correlations that probably the agents will be the only users of the blockchain capable of maybe running some complex strategies because they will be too complex for humans I think we're all discovering right now the correlations between Libra and Melania and about 90 other projects in the space and so that's going to be my who here has traded meme coins how many how many of you have made money on it net net pnl net pnl god bless you sir let's whoever can call the department of justice it's that guy right there I'm just kidding but oh man okay so you know just like the market backdrop is that there was this huge boom in crypto AI infrastructure in March of last year that went up that went down and then people discovered AI agent coins with virtuals and some other things around it that has gone up and has gone down in large part because of the connection to kind of stuff on Solana and the meme coin controversies with Kelsier and so on I think there are profound long term trends going on right so like these market bubbles or like speculation moments are really things that will pass as the secular adoption of the technologies that we're talking about increases but we it is painful it is super painful for people obviously who participate and as an investor I have to figure out what's the real commercialization model here and so Philip I want to kind of go backwards probably from you as well you know one simple mental model is there's manufacturing of stuff and there's distribution of stuff right and so crypto is good at manufacturing financial products like the banking industry was before the big open AI company the big tech companies like open AI are very good at manufacturing foundation models which are kind of the core the core intelligence of the AI sector and then agents are a productization that distributes those things right so you you talked about being able to access trades or if we plug in agents to oracles or if we give them new skill sets because they have your private data and they live on your phone whatever it is agents are a way to distribute that so we kind of know the value chain a little bit but we don't have a great sense of how these things get commercialized and so I want to go back to the recent AI agent market moment to ask like what do you think of the financialization that we saw like is it the right thing for agents to have a liquid token supply and for that thing to be the main way that they're traded you know is the ownership model of agents do you think correct like should we be pump funding tool you know like these pools and that's that's the way you hold an agent is the way for agents to make money to take a share of trading fees or should it be payments you know you've spent a lot of time kind of staring at social media attention that is kind of a proxy for the value capture or that that these agents generate but surely you must think you must also think about like what these things are worth so can we start there and then we'll kind of back solve into what other crypto AI stuff should be should be worth in the long run sure sure thank you yeah so basically as you said like the attention is currency that was the like foundation idea of running cookie.fun to like provide it in a very useful way for people so they can understand how much attention specific agents are actually covering among like crypto Twitter how do they actually get the attention can you just quick side yeah so basically they are active on Twitter and this is like applicable for probably 95% of them so they are getting attention on Twitter and they are providing something valuable theoretically AIXBT is probably the best example to refer to which became like probably one of the most known crypto KIO worldwide thanks to providing alpha thanks to providing very summarized information and intelligence basing on different data he is built on and I think this is pretty interesting business model because they have like AIXBT has this token gate terminal with even more alpha and like customizable alpha that you can ask for and he will provide you even like some reports about that just to kind of slow you down because I don't know if everybody is following like not because you're not explaining it because it's complicated so the agent is sucking in data or like text from a bunch of Twitter accounts yes there's a set of Twitter accounts that about 400 I guess how much 400 Twitter accounts that generates market views whether or not those are good market views is a question mark you know in traditional finance you'd have equity research right so you generate the market views then the agent is sucking in the data because data is not the new oil and then it's trained on it or it's tuned on it and then it can output a up-to-date market view when you talk to it yeah and the market values that a lot almost one bill I guess at the peak so if you have a token of like AIXBT you can access their terminal to access like even more data and like more insights generally and more intelligence you can ask about anything so this is like one approach I would say generally in terms of tokenization and value transaction in crypto I think again that the blockchain is just a perfect environment for the agents to transact between each other not specifically to like monetize them but like to transact the value because they cannot do it easily in web 2 there are no rails for doing it agents cannot have any identity so actually they are out of the bank system whereas in web 3 they can have multiple wallets and they can manage them and this is I think a very exciting point to actually rise in terms of the monetization we will see those implementations that probably different agents will be approaching differently but having this foundation that they can do anything with owning any token they can create some vaults some staking strategies they can even provide some its own solutions for example with different tokens that they have so right now I would say most of those tokens are not required and not necessarily needed for those agents but I believe that in the future we will discover many use cases where those tokens will be useful and will be just a transaction value and currency between those agents so they can exchange between each other and so on Ben how much of this story do you align with and which do you think will in what order do you think this will happen oh sorry Mark okay yeah you said Ben no no so I think it's pretty interesting because everything we just discussed right now the specific agent use case was very novel right and very highlighted on that you know scraping let's say Twitter for financial transactions and flow and I thought it was interesting you know one example you said earlier which was oh yeah eventually maybe these tokens will have value and kind of swapping it definitely reminds me of you just swap token with let's say NFT and it's kind of the same in terms of what we imagined about a few years ago right and so I think it's pretty clear just from a market standpoint that currently you know agent and how their utilizations and where they are now is still very early and we're developing and trying to improve the overall use cases which is why we need better data better different identifications of how they're structured and labeled and really I mean this is kind of the difference between us having a proof of concept with a very strong let's say large language model that ChatGPT built or that's utilized from that but then now let's get into the weeds of specific use cases so to me what I'm really interested and excited on a personal level is really seeing these businesses really have that application and developing that model with all their own their data and being able to really apply this extract that value with the agents to help them execute to help them really develop some of these efficiencies that we all envision can happen right and so you guys see a lot of different companies in this value chain how skilled do you think the agents become and on what time frame I think the time frame front it's really interesting because if you even just say blockchain people from the trad fi or you know institutional side they will say it's still early like we're still proving that there's utilization and use cases right I thought it was interesting earlier Philip said that oh yeah block chains meant you know for utilization of AI or agents for that development but in reality I mean it's a ledger right like it would be good to put your real estate on there because you need to know who owns what and it's transparent it can't be changed right there's specific use cases for each tech but the question is is it worth it to change right and so you see so much tech currently in not innovative spaces in banking in aerospace with airlines not updating their 1970s tech and still having that issue right and so I think within the next you know six months you'll see quick developments within the AI models and efficiencies and there's going to be maybe new more efficient novel use cases but kind of at a scale like probably not but that's why we're really excited about near being highly scalable and really being able to support and the connective tissue to really help execute every aspect of that as they improve their products and have better data they need to have better models and you need to execute more cross-chain transactions maybe from fiat to any other asset any new asset and being able on the back end to power all that and support that is really what we're about and why when we say near is a blockchain for AI it's kind of confusing because what does that even mean but then once you go in deeper the whole idea is having that infra and that AI piece to connect everything to connect the on and off ramps across different chains and really support and validate all of that so that's what we're really excited about and a lot of announcements coming up within the next few weeks and so happy to share more cool we're coming up on time but I want to give Magnus and Anna kind of the closing word on these commercial models and monetization you know and like do we need tokens for this stuff or is the nectar of speculation just too delicious to put down I'm feeling moody a little bit maybe Magnus how do you think about the commercialization of the data on your side and then Anna take us home after that yeah I'll talk about how we think about it at Blocksense in a minute first I just want to give a perspective on the agent landscape generally so I think commercialization slash monetization and financialization are two not necessarily 100% overlapping things and what I mean by that is you could financialize an agent and a lot of the crypto agents out today they're essentially that right it's an agent with a meme coin attached and the financialization there is just like the mind share like the attention that that agent is getting but it doesn't necessarily tie to the utility of the agent versus commercialization I think some of the projects that are looking a bit further afield further in the future are actually looking to build or like have frameworks out there that allow people to build agents that generate utility themselves right so they actually generate revenues they have control over their own wallets and they are able to interact on chain in such a way that they can build their own revenues and then the commercialization there would be potentially a model that looks more like a sharing of the revenue or dividends or something like kind of more closely approximating how business everywhere outside of crypto works which is like you try to generate cash flows and then you know the investors in your project kind of hopefully get rewarded for let's create real economic value Anna last word yeah I guess in terms of like the core economics it's really about how do you turn data into an asset class that actually is like revenue generating right and so that can either be by selling data directly to web to AI companies right or it can be by tokenizing an AI model right so I think one good example that actually shows the full flow of value is the Reddit data DAO which has 140,000 users who kind of contributed their data there's a Google brain ML engineer who came in and was like hey I want to train a model on this data he didn't want to directly buy the data and instead was like I'm going to give you ownership of the model so every time the model is used the data contributors actually get paid out right in the case of that he trained a model that was just good at shitposting because it's Reddit data right so quite early but if you compare it to like open AI like they're doing three four billion dollars in revenue from having the best AI model so I think that's sort of the model of economics that I expect to play out in kind of crypto AI in the next two or three years I'd say fantastic thank you so much I think the perspectives were really broad and different and I'm glad that we were able to open up these themes because it is a pretty profound moment I've said this in a previous session before but I think like financial nihilism is a poison in our industry we have a moment to marry crypto with AI AI is going to be the biggest driver of economic activity in the next 10-15 years and so we have like this moment to be the money financial rails and the economic incentive rails for the world to do this in an open source way it is completely up to us to fuck it up and we're doing a pretty good job as an industry of getting there but you know companies and projects like the ones on this stage are doing real work and so I just want to express thanks to the entrepreneurs that are taking real risk and for people to continue to be interested in this topic and pushing it forward so thank you thank you thank you everyone for being out I have to see you I have to see you I have to find out in this I have to see you I have to I have to I have to I have to see you