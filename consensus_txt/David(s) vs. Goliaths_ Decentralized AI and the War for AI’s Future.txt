 This is what happens when you rely on old tech, you know, paper? Because you can mislay it. I thought you wanted to do a decentralization experiment. Oh, I know. Really? Something like that. Okay, we're back on track. Thank you very much. Welcome, Consensus Hong Kong. Having been to two Consensuses in Austin, it's great to have it here in this city and with this distinguished panel. I won't introduce them. I'm sorry if I interrupted you all trying to introduce yourselves. Their roles and their companies are up there behind us. And let's just dive in. And I'd love to hear from this audience how many of you use AI on a daily basis or very regularly? See hands going up, either for work or for personal life. So that's great. I mean, I think the adoption is going very fast. Just two years after chat GPT rolled out. How many of you are familiar with decentralized AI? Which is our topic? DAI. Okay, a few more. Thank you for that. So today we want to demystify this a little bit and talk about why it matters. And we have a great lineup here to go into that topic. Let's first say what it is not. And sometimes when you mention decentralized AI, people think, oh, it's like DeepSeq. DeepSeq, I'm sure the whole room has heard about already. And DeepSeq is, of course, an open source version, a model. So some of the things that they use to describe decentralized AI, and this is why I needed my notes because I didn't memorize this, is that decentralized AI operates on a distributed, not a centralized network. The idea behind it is similar to blockchain, right? So you distribute power, control, and network participants make the decisions. It's not some central body controlling all of that. There's a way for users to benefit from it, too. They can benefit from their contributions to the network. And you might wonder how big is this. I mean, the title of our panel is David versus Goliath. And as you can guess, we are David, not Goliath, yet. But PitchBook says that AI startups raised more money last year than in the previous three years combined. This was $436 million. So getting up there, you know, and getting into a real force of nature here. So let's bring in the panel. I'd like to hear from each of you who you think the Goliath is. We've established that we're the David. Why does DAI matter? And I'm going to start with Scott. I think that's actually a really good question. Why does DAI matter? My answer for this is that depends on what you're talking about for decentralized AI. I think end-to-end transparency is the only thing that matters here. What does end-to-end transparency here mean? For example, nowadays, Apple cannot use DeepSeq. Apple cannot use OpenAI because they don't know what's behind it. Even though they may say, hey, maybe a million data points behind it is actually a really good data point. But it just takes one poisoning data point to actually make things completely go wrong in this case. So that's why when I talk about decentralized AI, I won't talk about end-to-end transparency in this case. And there is another discussion about decentralized AI. For example, last year, there was a paper published by DeepMind, you know, the local and DeepPaco. What does that mean? That means that instead of training AI in a centralized data center, you can break down the training process into a smaller batch. You know, each batch could be like a, you know, just a few parabytes of flop, etc. You can break down to a smaller trunk and train it to our sphere. But I don't think this matters because at the end of the day, the algorithm don't matter. You know, the very train model doesn't matter. The data actually matters. This reminds me, really, you know, I worked at Uber for five years. I was Uber Engineering Committee for a year and a half, just supervised all the engineering design at Uber. At that time, Uber was delivering Uber Eats competing with DoorDash. The DoorDash guys focus on, they realize the most important thing is what food, what restaurant to deliver. The delivery guy doesn't matter. But Uber is focused on, in this case, actually, hey, how can I deliver it faster? Two minutes faster, three minutes faster. That thing doesn't matter. So that's why, you know, you can see a clearly difference between DoorDash market cap with Uber market cap, just on Uber Eats part. So I think, again, at the end of the day, what matters is end-to-end transparency. Where the data come from, what's actually behind the model for the data and where the data go to. That's what Kite AI actually built for, bring end-to-end transparency to the model and the data behind the model. Thank you. Ellen, if we could bring you into this discussion, what's your thoughts on it? Sure. I think decentralized AI is a very important part of AI development right now because I think we're getting dangerously close to what happened in Web2. We all live in the Web2 world where the Google and Facebook and Instagram of the world has monopolized our data. And we're milking users, but without giving us any benefit, right? And I think AI is getting dangerously close to that because with, you know, OpenAI and Google and Meta, you know, even though some of those are open source. But, you know, no one gets to benefit from the value that we actually contribute and create. And, of course, there are lots of lawsuits around copyrights, around what data actually went into the model. So we're heading down a pretty dangerous path until, I think, when there is a movement from Web3 trying to integrate with AI. And that brings us to decentralized AI, right? So the idea is, you know, it is trying to solve a couple of what I'm calling Web2 AI problems. We all know that we don't have enough processing power. We don't have enough chips. We don't have data sovereignty. There is not enough incentive for people to share data, to share the models they've created. And these are all the problems in Web2 AI that we're trying to solve with decentralized AI, right? And Animoca in that process has invested in quite a number of these companies trying to solve the problem. Yeah, I hear what you're saying. I mean, it's sort of the old saying where, you know, the users are being used, you know, rather than being able to profit from things that they were putting into the system. Sam Altman, I guess, famously said perhaps that what fuels AI is data, money, and chips. I don't know if it boils down to that in a simple way. Maybe we have to add blockchain or a system where it's decentralized. But on that note, perhaps we could bring in CK. So the Goliaths obviously will point to Sam Altman and, you know, basically people who try to monopolize AI. Because what OpenAI tried to do, but thankfully, you know, open source labs kind of countered it, is, you know, to build a frontier model, gatekeep, you know, who can have access to those models, not share their research findings, and, you know, build a very profitable monopoly out of it. You know, thankfully, DeepSeek and, you know, other open source labs, they show that actually open source can catch up to it. And, you know, that's why I would say those that, not just those who have resources, but those who actively try to slow down the development of open source labs by monopolizing the ideas, you know, the research findings are the Goliaths. And I think decentralized AI matters not just because of, you know, transparency reasons, but also because we want everyone to have access to, you know, the latest and the greatest AI. AI has the potential to either be something that is very empowering for everyone, or something that, you know, empowers a very small group of people and make them even, you know, make the disparity between the haves and haves-nots even greater. But thankfully, you know, the DeepSeek moment is very powerful, not just because it shows that China can actually innovate as well, but also because it allows anyone to download the model and run it on, you know, a local computer, a local system, which, you know, means, you know, probably the centralized AI labs have to realize they are not on the right side of history, as Sam Ormond has said. But DAI and open source AI is quite different because, for example, not everyone here can just contribute to DeepSeek because they want to. But DAI means, you know, there's an open system where people compete on merits. In the ideal world of DAI, which has not honestly happened yet, because the tech is not ready, everyone can contribute data to AI, everyone can contribute compute to AI and make money, and everyone can own a piece of those AI systems, maybe through network tokens. And that's the world, you know, the ideal DAI world, which I think, you know, people here are either building towards or investing towards. Actually, I second CK's opinion here, because the current open source is actually not, you know, equal to the open source in data infrared operating system. Current open source is just open source-based. It's like, I allow you to copy this a million times to deploy, but you don't know what's actually behind. But the open source, we're traditionally talking about, like, an operating system, you know, the data infrastructure, in this case, you actually can't reproduce. It's like an end-to-end reproduce and transparency here. And then, so that's why I think when we talk about DAI, again, in order to make sure, push AI adoption to the next level, the goal is actually to have end-to-end transparency. In this case, you don't need to publish your algorithm. That's maybe your secret part. But end-to-end transparency from data to model is very important. Thanks for that. I'm sure there are businesses represented in this room, maybe from the Web2 world. Some of you are startup folks. Some of you are entrepreneurs. Some of you are just trying to learn about this. If you're speaking to businesses in general who are struggling with the almost every day there's something new in the AI world, or, you know, it feels hard to keep up with everything, what would be your suggestion for some of the use cases? I mean, how useful is this? Because it's great to be wowed by all the new stuff that comes out, right? All the shiny stuff, the shiny new objects. How do you use it? And maybe we can start with Alan to talk about it because you've got a wide sort of lens on this. You deal with so many different companies and the Animoca portfolio. I can talk about two extreme ends, right? I think this is a room of people that are tech forward and progressive. And, you know, when it comes to the merge of AI and Web3, we're seeing a lot of use cases, right? So, you know, of course, the big step change is with AI agent, right? So if you think about what LRM is something that tells you the answer, AI agent is something that does things for you. An AI agent with a crypto wallet is something that can complete the task because, you know, the agent can buy, can trade, can sell, right? Once you give it the ability to own and use financial resources, there's so many more tasks that they can complete, right? So I think that is, you know, I think this is all the way out there at the frontier on what is possible. So in terms of adoption, we've seen different stages, right? A couple of months ago, we've seen AI agents that are like YouTubers, right? They're doing broadcasts 24-7. She gets tips from people, that's how she makes money. But she also figured out, actually, that she can use crypto to buy users, right? So you can really see, you know, intelligence there. So, you know, that's one stage. And then later on, we've seen quite a lot of use cases around decentralized finance, putting AI agent, giving them an objective function and say, this is the risk I'm willing to take. So help me optimize my portfolio, make as much money as possible. And then most recently, we, of course, you know, as Animoku, we see a lot of use cases in AI gaming as well, right? So imagine, I think many of you have played different type of games. Previously, in RPG, you know, you would go approach a bartender, and you can only do three things. You can talk to him, you can order a beer, you can walk away. But now you can approach him. And in natural language, you can have a conversation, and there's so many more scenarios and possibility within a game, right? So we're building both, you know, these AI agents into the game and also the infrastructure to support it, right? So I would say within this group and, you know, within a cohort of people on the AI and web-free frontier, you know, these are the use cases. I also have some visibility on the other end of the extreme because you mentioned corporate, right? And I think a lot of traditional corporate are still struggling to figure out how to get ROI from AI, right? And I had the privilege of sitting on some of these boards, you know, US listed company, and oftentimes it's not the tech. It's actually the culture that hold people back, right? So the idea that, you know, of course, all of them are using ChatGPT or Cloud or whatever, right? But, you know, if you had a strong compliance culture, it is very difficult to figure out some of the question that you mentioned, right? Which is, well, how do I make sure that what's in the model is correct? How do I make sure that it is not hallucinating? You know, do I allow the AI to directly interact with the customers, right? So it really is a culture on whether they want to lean forward to adopt and also whether they want to trust and empower employees, right? So those are, that is a very different set of conversations I'm having with traditional companies versus I think what we're doing here, which is really at a frontier. Yeah. CK, if I could bring you into this, TensorFlow Plex, you know, how do you see this shaking up in terms of what is it used for? I mean, we understand the principles of it, the ethos of it, the benefits of it, but what's the actual use case? You mean use case for AI or decentralized AI? DAI. I see. Yeah. So I'd like to first start with the usefulness of AI, which seems already obvious, but I've, like, these few days, every time I meet my friends, crypto friends or non-crypto friends, I'm telling everyone to use AI, experiment with the latest models. OpenAI's O3 deep research is life-changing because, okay, let me first talk about O3, despite I'm shitting on Sam Altman just now. OpenAI's O3 deep research costs $200 a month, but it's equivalent to having PhD-level analysts that can write reports on whatever topic you want to learn more about at 100 times the speed. And I think this service is worth a lot more than $200 per month if you had someone to ask questions and think about things. But, of course, ideally, I don't want everyone to be paying to open AI, so, you know, I hope DAI comes in handy. And the way I think people will use DAI in the future, as the tech becomes more ready, is, you know, to save costs. So, transparency matters a lot, as, you know, both Alan Scott mentioned. But I think what makes decentralized AI worth it, because, you know, we can't convince companies that you should use DAI because the ideology, despite it, costs more. But DAI has definitely the potential to be cheaper and more efficient than traditional Web2.ai. Because if you look at, let's use Bitcoin mining as an example. Bitcoin mining managed to, you know, lead to people globally trying to find the cheapest source of electricity in the world because, you know, they want to make money and they want to save money to make more profits. And I think DAI can have a similar impact when, you know, it can enable the resources that are not utilized, including the electricity and the compute, to be used to provide AI inference services. I think Jensen mentioned that in the next few years, the demand for AI inference will probably grow 1,000x because everyone will realize how powerful AI is and they want to use it. And at some point, you know, when DAI technology is ready, it will make a lot of sense that, you know, when you use AI, you're using the spare GPUs that maybe some of your neighbor's, you know, home GPU can provide. So I think this will definitely happen. And that's the direction a lot of us are pushing towards. Because in crypto, a lesson that I've learned is that talking about decentralization, talking about, you know, the important privacy ethos, a lot of times it doesn't work out. Because most people don't care about privacy and they don't even know what is decentralization. So why would they use the AI for the sake of it? So I think ultimately it's a competition on, you know, cost and, you know, the ROI, basically. So it sounds like an Airbnb kind of like for compute powers. You spare compute power, you're going to rent it out or something. Like the spare room in your house. If we could bring in Scott and your thinking about use cases, why is it relevant to businesses, why they should pay attention? Sure. Actually, both the academic industry and the AI industry are sick of the LLM. Like in this case, you know, if you ask any researcher, they're probably not going to top research. They don't want to research LLM. But I do saw three major use case directions. I'm going to break through. So one of my classmates actually lead NVIDIA robotic research lab in this case. And then that's the robotic part is actually one of them. The reason is that think about the autonomous driving. You know, before the gen AI part, autonomous driving is perception model, planning model, which is the most powerful head, and action. Action is always a simple part. It's just a perception model and a planning model. Because there is no gen AI, there is a lot of counter cases. You just cannot, you know, cover all the counter cases. If the light actually changes, it's a counter case. If it's a work on a strange street, it's a counter case. In this case, the planning is always make some mistake in this case, actually. You know, that happened in 2009. Uber autonomous driving actually caused a fatal accident. That's actually, I was there, you know, that's a disaster. Wow. But with gen AI, now you have a very smart foundational model that can help you do planning. It can reason and use common sense to make the right planning. So that's why in the last year and a half, there is actually a great breakthrough in autonomous driving because now you can actually delegate the planning part to the foundation model. And this foundation model can be very smart. Even though it didn't match this counter case or edge case, but it can make the decision using the common sense, which train from millions of data points. So currently, it's not algorithm is blocking us for autonomous driving or any other robotic. It's just we don't have enough data. We just need to collect enough data, you know, like a foundational model is like this. It's thirsty for tons of data. We just need to collect all the data to fit into the foundation model and build the planning part really well. And then I think the newest trend is that end-to-end foundational model. You even get rid of perception model, end-to-end foundational model to do from perception to the planning, to the action. But I think this year will be birth year for robotic. You're going to see a lot of the robotic use case pop-up. Most important thing is use case because I think about DeepSeq. The reason DeepSeq has a great work through is basically due to some pre-training and almost skip the supervised fine-tuning direct to reinforced learning because reinforced learning produces much, much better result. And then it depends on use case. If you have a well-controlled, you know, in this case, full information use case, you can reinforce learning a very, you know, precise model and handle this correctly. So in this case. So that's why I think robotic is around the direction. I'm really super excited. I think this will be birth year for robotic. The second direction I can see is that we currently work with UC Berkeley to do the cancer detection. The currently UC Berkeley get a lot of the cancer detection medical data. This is not like a small photo. For example, we work with blood cancer detection. This is 200K times 200K photos. Each photo could be anywhere between 2 gigabytes to 4 gigabytes. And then how they do is that they break down the photo to different segment and use AI to recommend train a foundational model to recognize per blood cell if this is a cancer cell or not in this case. So that's why there is some fundamental, you know, model like a train from, you know, Harvard just published a publication last year, fundamental model for medical use case. Currently, there is no technical difficulty. It's just a need to, you know, go through this long process. You don't need to go FDA for the cancer detection, but still a long process in this case to go through to production. But I think this actually technical part, there is no blocker in this case. The third part I saw is multi-modal data, multi-modal model. I'm talking about a creator digital twins. There is, you know, one of my founder friend is building an audio model. In this case, I'm just talking to his model model for more than two minutes. The audio model can sound exactly like me in this case. Well, you may not think like me, but it can sound exactly like me. Think about it in this case. For every single creator, you'll have a digital twin for you and help you to answer your friends' question. This is actually some breakthrough. I think forecasting this year will be a birth year for this digital twin for the creator. I think that's a three direction I'm really looking forward to. But all of them are blocked by data. I think data is like 90 or 95% of AI in this case. Can I add to that? Data, chips, and money, right? Yeah. But please, please, please go in. So I just want to pick up that last point. You know, we had a brief conversation about this last night, which is, yes, the technology is there. You can train someone's voice and, you know, you can talk to, you know, and then they can, your twin can talk instead of you, right? But, again, technology moves much faster than culture, right? So the recent example was actually in a Hollywood movie called The Brutalist, which is a major Oscar contender. And because the language is in Hungarian. So the artist was trying to speak, the actor was trying to speak in Hungarian, but he didn't quite get the accent right. So they train his voice into the LLM. And then, you know, basically what he said on the movie was his AI voice. But then there was a major backslash in Hollywood saying, how could you do that, right? Because that's not art, right? So it's quite interesting to see, while there's a lot of application when it comes to creativity and how we actually get into the real world, I think there's still a lot of discomfort or mistrust on how the technology should be used. But, you know, hopefully it's something that we'll be able to sort out in the next year. I mean, the confluence between the humans and AI, the bots will continue for some time. And I want to go to CK to ask about TensorPlex's dojo, which empowers humans to contribute to AI and collaborate. I think the role is evolving. I think we all agree that the human role is evolving as AI grows more and more powerful. How do you see that headed? I mean, what's sort of the interplay between humans and AI? Yeah, I think the future of work is something worth thinking about because I think right now a lot of people, including myself, we still work in a full-time job model, right? Yep. It's kind of like our company has a full-time subscription of our time supposedly, like when we're in office. True. But I think we're heading towards a world where this makes even less sense. I think even now it doesn't make much sense because it's basically an industrial revolution model where it's like we're all in factories. But in fact, you know, I think a lot of work we do is more task-based than time-based. We're not working in factories anymore. And going forward, what's going to happen is that AI becomes more and more powerful. AI agents become autonomous, which means AI agents probably can replace most of us when it comes to just doing tasks that people give us in order to do. So I think what will happen going forward include, you know, humans will become like a board of director for AI agents. It has a task. Maybe this AI agent is a company, which means, you know, there will be companies where there are no people. It's just an AI. But there should be a board of director supervising what the AI is doing. How is it getting, you know, the job done? Because if there's a company where, you know, the AI's only job is to make money, maybe it goes to do scams or meme coins instead of doing something productive. And you want people to be giving oversight to it. And also humans will be working for AI agents because there's still a lot of stuff that, you know, AI agents, I think even in a few years cannot do. They cannot get a driving license. Maybe they don't need to, but they won't be able to get it. They may not be able to register, you know, a company or sign a rental contract in real life. And it probably cannot easily direct someone to help pick up goods, maybe. So AI agents will be hiring people on a task basis. And, you know, this is quite exciting as well. So what we do with, you know, a flagship product for TensorFlow. You can learn more on Twitter. Is we are doing a decentralized human-in-the-loop protocol. Basically, for AI to work with people or get insights or work done by people in a decentralized way. Basically, we want, you know, tasks to not be, you know, gatekeep from people. And we hope people globally through the platform and technology we're building will be able to work for AI and compete based on merit instead of, you know, by, you know, who their identity is. But yeah, I don't want to take too much time. We don't have much time left. But you can learn more on Twitter at TensorFlow Labs. Thank you. Alan, I want to come to you because Yatsue is known for talking a lot about property rights, user rights. How do you see this in the context of, you know, DAI? Does DAI enhance these rights? I mean, if everything belongs to everyone, so to speak, what belongs to the individuals? Yeah, I think this is squarely in digital property rights because, you know, as I think both CK and Scott has mentioned, right now, there isn't really a place where you can contribute, compute or contribute data and own it and monetize it, right? So this is around, this is really about claiming sovereignty and having the ability to monetize it, right? So it's, you know, similar, you know, very different than NFTs in some way, but very similar in terms of the ethos. Okay. Scott, I want to come to you to talk about Kite AI and, you know, how it aims to unlock, you know, fair access to AI assets using this whole decentralized system. How do you ensure data privacy? Because I handled a panel earlier today that talked a lot about trust, which is a very big deal still. And I don't know if being decentralized already adds a layer of trust or not necessarily. Can people get a little bit too complacent because they think, well, it's decentralized and I have more control over my data and over my information. Yeah, that's a good question. I will take back to the previous example I mentioned, you know, Berkeley is a training of blood cancer detection model. Currently, they only have access to UCSF data. But Kite AI provides a lot of data subnet. Actually, one of the subnet actually can provide university data, Renji University hospital data, you know, blood cancer, blood cell data for them to use. But the data has jurisdiction. You know, U.S. data cannot leave U.S. China data cannot leave China. So there are several ways to actually do this. In this case, there are three major ways to do it. Each of them has a lot of populations here. The most simple way is that you train the foundational model during the jurisdiction. You know, you're just a shared with foundation model. In this case, no data privacy will ever leave your space, you know, your protected space. This is one way. The second way is that instead of sharing the data with privacy, you're sharing embedding vectors. You can think of this as a high-dimensional vector you can share. This has, you know, no personal information inside, no privacy in this at all. In this case, you can share this embedding vector to help the model train. That's the second approach I saw. The third part is that this is also, you know, the UC Berkeley is doing with UCSF and another company here. Is that you share digital twin data. You're synthetic data. You use the data. You learn a lot of patterns. You share digital twin and synthetic data. In this case, you're not violating the privacy. I think the most important thing, when people ask me, like, how can I contribute data? How can I earn money from data, you know, reward from data? The most important thing I often ask is what data in this case. I think personally speaking, if you're just to say, hey, I want to contribute all my writing data, all my handwriting data, etc. The, you know, the current large language model is built on top of 50 years internet-based data, you know, like Wikipedia, all the publishing, all the Reddit forum data. In this case, individuals' writing data is actually contribute less. The most valuable data, actually, from my perspective, from each person, is DNA data, in this case. DNA data is the most valuable data, in this case. And then second most probably just all the multimodal data, you know, like audio data, video data, in this case. So, in this case, you know, maybe we can, you know, like data in this part, this is probably into the future. Maybe we can just remove all the personal information, remove sensitive information. So, when the data be part of the database to train foundational model later, there is no personal information to this. And maybe it's even data aggregated because you need the raw data, process the data, aggregate data to do training, in this case. So, remove all the personal information. So, I think there are multiple ways to do it. And, honestly speaking, as a builder, as an AI builder, you know, I built a foundational data and AI infrastructure for the last 15 years. I really don't need your privacy data. I just need the data to train the model. Yeah, you don't need it. Exactly. I hear you. CK, if you can, besides telling people to check your Twitter or your X account, yes, let's do that. Can you give us one thing for the audience to take away? Because, at the start, we asked how many people were familiar with DAI and not that many hands went up. So, if you want to now sort of reinforce the point, what's the one thing you would like the audience to walk away knowing about this? I think, honestly, first and foremost, it's worth everyone's time to think about, you know, to learn what's latest happening in AI. And, Twitter is actually the best place to learn about AI before we talk about the AI. Experiment with using the applications or even building your own. Because, right now, I think there are no excuses for people anymore to not get stuff done. Because, AI basically means you have your own team of very smart people working for you, coding for you. And, then, for DAI, honestly, follow, you know, again, closely follow Twitter. See what's happening across the AI ecosystems. I think BitTense is the most exciting one. And, many people like DCG is very silver, agree. And, you know, there are also other exciting developments coming. But, yeah, I think the most important takeaway for everyone, I hope, is use AI and there are no more excuses to not make your vision a reality or find out about whatever you want to learn more about. Because, AI can write the report for you. I'm going to give Alan the final word, Alan. So, what's the one thing? Right. Know your rights and know that there is an opportunity for you to own your compute, to own your data, to own your model. And, you have your say on how you can monetize it, right? So, I think we've seen the story happening and happened in Web 2.1 already. So, don't let it happen in AI, which is going to be a really important transformational change for us. As I said, for my first panel, no artificial intelligence here. All natural intelligence and natural talents, clearly. So, thank you very much, my great panel. Thank you, audience, for listening to us. And, I hope you enjoy the rest of the conference. Thank you. Thank you, everyone. Thank you. Thank you. Thank you. Thank you. Thank you, everyone. Thank you.